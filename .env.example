# Example environment file for NKI-LLAMA
# Copy this to .env and update with your values

# Hugging Face Configuration
HF_TOKEN=your_huggingface_token_here
MODEL_ID=meta-llama/Meta-Llama-3-8B
MODEL_NAME=llama-3-8b

# Inference Configuration
INFERENCE_PORT=8080
MAX_MODEL_LEN=2048 # used by vllm- ensure it is the same as seq len
SEQ_LEN=2048 #used by main.py

MAX_NUM_SEQS=4
TENSOR_PARALLEL_SIZE=8

# Dataset Configuration
DATASET_NAME=databricks/databricks-dolly-15k

# Neuron Configuration
NEURON_RT_NUM_CORES=8

# Jupyter Configuration
JUPYTER_PORT=8888